{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activity labels as defined in activity_labels.txt\n",
    "activity_labels = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING', 'STAND_TO_SIT', 'SIT_TO_STAND', 'SIT_TO_LIE', 'LIE_TO_SIT', 'STAND_TO_LIE', 'LIE_TO_STAND']\n",
    "activity_labels = {k:v for k,v in enumerate(activity_labels, start=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data before mod (3162, 561)\n",
      "train_data before mod (7767, 561)\n",
      "test_data after mod (3162, 561, 1)\n",
      "train_data after mod (7767, 561, 1)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path, header=None, delim_whitespace=True)\n",
    "    return data.values\n",
    "\n",
    "def load_set(path, x, y):\n",
    "    data = load_data(path+x)\n",
    "    labels = load_data(path+y)\n",
    "    return data, labels\n",
    "\n",
    "train_data, train_labels = load_set('HAPT Data Set/Train/', 'X_train.txt', 'y_train.txt')\n",
    "test_data, test_labels = load_set('HAPT Data Set/Test/', 'X_test.txt', 'y_test.txt')\n",
    "\n",
    "print(f'test_data before mod {test_data.shape}')\n",
    "print(f'train_data before mod {train_data.shape}')\n",
    "\n",
    "#reshape the data to add a features dimension (features = 1)\n",
    "#https://stackoverflow.com/questions/43396572/dimension-of-shape-in-conv1d\n",
    "train_data = np.expand_dims(train_data, axis=2)\n",
    "test_data = np.expand_dims(test_data, axis=2)\n",
    "\n",
    "print(f'test_data after mod {test_data.shape}')\n",
    "print(f'train_data after mod {train_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7767, 1)\n"
     ]
    }
   ],
   "source": [
    "#input shape\n",
    "timesteps = train_data.shape[1] #561 timesteps\n",
    "features = train_data.shape[2] #1 feature\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 559, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 279, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 277, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 136, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 68, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 68, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8704)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               4456960   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 13)                429       \n",
      "=================================================================\n",
      "Total params: 4,662,989\n",
      "Trainable params: 4,662,989\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(filters=32, kernel_size=3, strides=1, activation='relu', input_shape=(timesteps,features)))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(filters=64, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(filters=128, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(256))\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Dense(13)) #not sure why the dense layer has to be 13 instead of the 12 activities\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3162/3162 - 2s - loss: 2.5455 - accuracy: 0.2198\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = model.evaluate(test_data, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false predictions:215\n",
      "true predictions:2947\n",
      "prediction accuracy: 0.9320050600885516\n"
     ]
    }
   ],
   "source": [
    "pred_outs = model.predict_classes(test_data)\n",
    "\n",
    "#test if the label matches the prediction\n",
    "false_pred = 0\n",
    "true_pred = 0\n",
    "for i in range(len(pred_outs)):\n",
    "    #print(f'test_label: {activity_labels[test_labels[i][0]]}\\npredicted_label:{activity_labels[pred_outs[i]]}')\n",
    "    if not (1 < pred_outs[i] or pred_outs[i] < 13):\n",
    "        print('prediction out of bounds')\n",
    "    if pred_outs[i]==test_labels[i][0]:\n",
    "        #print('true')\n",
    "        true_pred += 1\n",
    "    else:\n",
    "        #print('false')\n",
    "        false_pred += 1\n",
    "print(f'false predictions:{false_pred}')\n",
    "print(f'true predictions:{true_pred}')\n",
    "print(f'prediction accuracy: {true_pred/len(pred_outs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 577us/sample - loss: 0.6208 - accuracy: 0.7570 - val_loss: 0.2981 - val_accuracy: 0.8782\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 4s 459us/sample - loss: 0.1861 - accuracy: 0.9261 - val_loss: 0.3525 - val_accuracy: 0.8605\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 4s 457us/sample - loss: 0.1346 - accuracy: 0.9484 - val_loss: 0.3656 - val_accuracy: 0.8719\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 4s 467us/sample - loss: 0.1220 - accuracy: 0.9526 - val_loss: 0.2278 - val_accuracy: 0.9216\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 4s 455us/sample - loss: 0.0967 - accuracy: 0.9618 - val_loss: 0.1981 - val_accuracy: 0.9292\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 4s 474us/sample - loss: 0.0814 - accuracy: 0.9694 - val_loss: 0.4132 - val_accuracy: 0.8865\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 4s 472us/sample - loss: 0.0753 - accuracy: 0.9714 - val_loss: 0.3039 - val_accuracy: 0.9058\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 4s 475us/sample - loss: 0.0726 - accuracy: 0.9737 - val_loss: 0.1819 - val_accuracy: 0.9481\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 4s 466us/sample - loss: 0.0682 - accuracy: 0.9737 - val_loss: 0.2069 - val_accuracy: 0.9336\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 4s 459us/sample - loss: 0.0505 - accuracy: 0.9789 - val_loss: 0.2172 - val_accuracy: 0.9320\n",
      "3162/3162 - 1s - loss: 0.2172 - accuracy: 0.9320\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, \n",
    "          train_labels, \n",
    "          epochs=10, \n",
    "          validation_data=(test_data, test_labels))\n",
    "\n",
    "test_loss,test_acc = model.evaluate( test_data, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
