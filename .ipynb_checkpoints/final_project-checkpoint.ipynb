{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activity labels as defined in activity_labels.txt\n",
    "activity_labels = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING', 'STAND_TO_SIT', 'SIT_TO_STAND', 'SIT_TO_LIE', 'LIE_TO_SIT', 'STAND_TO_LIE', 'LIE_TO_STAND']\n",
    "#activity_labels = {k:v for k,v in enumerate(activity_labels, start=1)}\n",
    "#print(activity_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaping data...\n",
      "adjusting labels...\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path, header=None, delim_whitespace=True)\n",
    "    return data.values\n",
    "\n",
    "def load_set(path, x, y):\n",
    "    data = load_data(path+x)\n",
    "    labels = load_data(path+y)\n",
    "    return data, labels\n",
    "\n",
    "#reduce the labels by 1 to match with the activity_labels and also to start labels at 0 to 11 instead of from 1 to 12\n",
    "def adjust_labels (labels):\n",
    "    for i in range(len(labels)-1):\n",
    "        labels[i][0] -= 1\n",
    "    return labels\n",
    "\n",
    "train_data, train_labels = load_set('HAPT Data Set/Train/', 'X_train.txt', 'y_train.txt')\n",
    "test_data, test_labels = load_set('HAPT Data Set/Test/', 'X_test.txt', 'y_test.txt')\n",
    "\n",
    "print('reshaping data...')\n",
    "#reshape the data to add a features dimension (features = 1)\n",
    "#https://stackoverflow.com/questions/43396572/dimension-of-shape-in-conv1d\n",
    "train_data = np.expand_dims(train_data, axis=2)\n",
    "test_data = np.expand_dims(test_data, axis=2)\n",
    "\n",
    "print('adjusting labels...')\n",
    "train_labels = adjust_labels(train_labels);\n",
    "test_labels = adjust_labels(test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get time of epochs to record training time\n",
    "#https://stackoverflow.com/questions/43178668/record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
    "class TimeHistory(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out n number (pred_range) of predicted values and compare them with test labels\n",
    "def predict(pred_range, pred_outs, test_labels):\n",
    "    #test if the label matches the prediction\n",
    "    false_pred = 0\n",
    "    true_pred = 0\n",
    "    #look at predictions for the first 25 values\n",
    "    for i in range(pred_range):\n",
    "        if not (0 <= pred_outs[i] or pred_outs[i] <= 11):\n",
    "            print('prediction out of bounds')\n",
    "            break\n",
    "\n",
    "        print(f'Test label: {activity_labels[test_labels[i][0]]}')\n",
    "        print(f'Predicted label:{activity_labels[pred_outs[i]]}')\n",
    "\n",
    "        if pred_outs[i]==test_labels[i][0]:\n",
    "            print('true\\n')\n",
    "            true_pred += 1\n",
    "        else:\n",
    "            print('false\\n')\n",
    "            false_pred += 1\n",
    "    print(f'False predictions:{false_pred}')\n",
    "    print(f'True predictions:{true_pred}')\n",
    "    print(f'Prediction accuraccy for first 25 values: {true_pred/pred_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(test_data, test_labels, train_data, train_labels, filters, kernel_size, dropout, epochs, predict=True):\n",
    "    #input shape\n",
    "    timesteps = train_data.shape[1] #561 timesteps\n",
    "    features = train_data.shape[2] #1 feature\n",
    "    \n",
    "    #model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=1, activation='relu', input_shape=(timesteps,features)))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=1, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(12, activation='relu'))\n",
    "    model.summary()\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "    #evaluate model\n",
    "    test_loss,test_acc = model.evaluate(test_data, test_labels, verbose=2)\n",
    "    \n",
    "    if predict:\n",
    "        #predict\n",
    "        pred_outs = model.predict_classes(test_data)\n",
    "        #display predictions\n",
    "        predict(10, pred_outs, test_labels)\n",
    "    \n",
    "    #train the model\n",
    "    time_callback = TimeHistory()\n",
    "    model.fit(train_data, \n",
    "              train_labels, \n",
    "              epochs=epochs, \n",
    "              validation_data=(test_data, test_labels),\n",
    "             callbacks=[time_callback])\n",
    "\n",
    "    test_loss,test_acc = model.evaluate( test_data, test_labels, verbose=2)\n",
    "    \n",
    "    training_time = sum(time_callback.times)\n",
    "    \n",
    "    return training_time, test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_unit_string(time):\n",
    "    return f\"Total training time: {math.floor(time/1)}s {math.floor(time%1 * 1000)}ms {math.ceil(time%(1/1000)*1000)}us\"\n",
    "\n",
    "class RunTests: \n",
    "    n_tests = 10\n",
    "    d_epochs = 10\n",
    "    d_filters = 64\n",
    "    d_kernel_size=3\n",
    "    d_dropout=0.5\n",
    "    \n",
    "    def test_param(self, filters=d_filters, kernel_size=d_kernel_size, dropout=d_dropout, epochs=d_epochs):\n",
    "        if isinstance(filters,list):\n",
    "            data = filters\n",
    "            data_type = 'filters'\n",
    "        elif isinstance(kernel_size,list):\n",
    "            data = kernel_size\n",
    "            data_type = 'kernel_size'\n",
    "        elif isinstance(dropout,list):\n",
    "            data = dropout\n",
    "            data_type = 'dropout'\n",
    "        elif isinstance(epochs,list):\n",
    "            data = epochs\n",
    "            data_type = 'epochs'\n",
    "        else:\n",
    "            print('no data type selected, running default...')\n",
    "            data = [1]\n",
    "            data_type = 'default'\n",
    "        \n",
    "        model_test_data = []\n",
    "        for index, item in enumerate(data):\n",
    "            model_test_data.append([])\n",
    "            for i in range(0,self.n_tests):\n",
    "                if data_type == 'filters':\n",
    "                    time, loss, acc = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=item, \n",
    "                                                dropout=dropout,\n",
    "                                                epochs=epochs)\n",
    "                elif data_type == 'kernel_size':\n",
    "                    time, loss, acc = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=item, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=epochs)\n",
    "                elif data_type == 'dropout':\n",
    "                    time, loss, acc = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=item,  \n",
    "                                                epochs=epochs)\n",
    "                elif data_type == 'epochs':\n",
    "                    time, loss, acc = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=item)\n",
    "                else:\n",
    "                    time, loss, acc = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=epochs)\n",
    "                test_output = {'time': time, 'loss': loss, 'acc': acc, 'test parameter': item}\n",
    "                model_test_data[index].append(test_output)\n",
    "        return model_test_data\n",
    "\n",
    "    #data is a two-dimensional list\n",
    "    def print_results(self,data, data_name):\n",
    "        print(f\"{data_name} test data:\")\n",
    "        for test in data:\n",
    "            for i in range(0,self.n_tests):\n",
    "                print(f\"{data_name}: {test[i].get('test parameter')}\")\n",
    "                print(f\"\\tloss: {test[i].get('loss')}\")\n",
    "                print(f\"\\taccuracy: {test[i].get('acc')}\")\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    def plot_results(self, data, data_name):\n",
    "        loss=[]\n",
    "        acc=[]\n",
    "        param=[]\n",
    "        for index, test in enumerate(data):\n",
    "            param.append(test[0].get('test parameter'))\n",
    "            loss.append([])\n",
    "            acc.append([])\n",
    "            for i in range(0,self.n_tests):\n",
    "                loss[index].append(test[i].get('loss'))\n",
    "                acc[index].append(test[i].get('acc'))\n",
    "        \n",
    "        fig, axs = plt.subplots(2)\n",
    "        axs[0].set_title(f'{data_name} loss')\n",
    "        axs[0].set(xlabel=data_name, ylabel='Loss')\n",
    "        axs[0].boxplot(loss)\n",
    "        axs[0].set_xticklabels(param)\n",
    "        \n",
    "        axs[1].set_title(f'{data_name} accuracy')\n",
    "        axs[1].set(xlabel=data_name, ylabel='Accuracy')\n",
    "        axs[1].boxplot(acc)\n",
    "        axs[1].set_xticklabels(param)\n",
    "        \n",
    "        fig.subplots_adjust(hspace=0.8)\n",
    "        \n",
    "        plt.show\n",
    "        \n",
    "runner = RunTests() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filters_data = runner.test_param(filters=[32, 64, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runner.print_results(filters_data, 'filters')\n",
    "runner.plot_results(filters_data, 'filters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropout_data = runner.test_param(dropout = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runner.print_results(dropout_data, 'dropout')\n",
    "runner.plot_results(dropout_data, 'dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel_size_data = runner.test_param(kernel_size = [2,3,5,7,9,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runner.print_results(kernel_size_data, 'kernel_size')\n",
    "runner.plot_results(kernel_size_data, 'kernel_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
